{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Main\n",
    "* In this notebook is possible to train and evaluate the agents. Then there is also a brief illustration on how the frames are preprocessed. \n",
    "* There are some pre-trained models available for Space-Invaders and Phoenix.\n",
    "* The agent can be trained on Space Invaders, Assault and Phoenix."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gym\n",
    "!pip install gym[atari]\n",
    "!pip install autorom[accept-rom-license]\n",
    "!pip install torch\n",
    "!pip install wandb -qU"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peppe/miniconda3/envs/my_env/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "A.L.E: Arcade Learning Environment (version 0.8.0+919230b)\n",
      "[Powered by Stella]\n"
     ]
    }
   ],
   "source": [
    "### EXTERNAL LIBRARIES\n",
    "import gym \n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from PIL import Image\n",
    "import wandb\n",
    "\n",
    "### INTERNAL FILES\n",
    "from src.variables import *\n",
    "from src.model import *\n",
    "from src.utils import *\n",
    "from torchvision import transforms\n",
    "import torch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enabling Weights and Biases to track the experiments\n",
    "* [Weights and Biases Project](https://wandb.ai/difra00/RL_Curiosity_agent?workspace=user-difra00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if wb:\n",
    "    wandb.login()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the training option:\n",
    "* load: Load a pre-trained model;\n",
    "* train: Train a new-one;\n",
    "* save: Select if saving the model after each new episode.\n",
    "* ext/intr: Select the type of training, whether using only extrinsic rewards, only intrinsic, or both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VARIABLES SELECTION #############################################################################\n",
    "load = True     # if load is False the model is taken with the random initialization of the weights\n",
    "train = True   # if train is False the testing mode is enables\n",
    "save = False    # if True, the model is saved after each episode.\n",
    "\n",
    "ext = True   # Extrinsic reward enabled\n",
    "intr = True  # Intrinsic reward enabled (Curiosity reward)\n",
    "###################################################################################################\n",
    "\n",
    "\n",
    "add = '.pt'\n",
    "if intr: \n",
    "    add = '_intrinsic' + add\n",
    "if ext: \n",
    "    add = '_extrinsic' + add\n",
    "\n",
    "\n",
    "# For SpaceInvaders there is only available a pre-trained model with extrinsic and intrinsic rewards. \n",
    "# It was only trained for 100 episodes\n",
    "\n",
    "model_load = './models/' + game[4: -3] +add\n",
    "\n",
    "model_save = ''\n",
    "\n",
    "seed_list = [30, 60, 90]\n",
    "\n",
    "if train:\n",
    "    for i in range(3):\n",
    "        agent = Policy(model_name_load = model_load, model_name_save = model_save, ext = ext, intr = intr, seed = seed_list[i], load = load, save = save)\n",
    "\n",
    "        agent.trainer(n_training_episodes=training_episodes, exp_name= 'exp_name{}'.format(i+1) ) # only extrinsic: 0, only intrinsic: 1, extrinsic + intrinsic: 2\n",
    "else:\n",
    "    agent = Policy(model_name_load = model_load, model_name_save = model_save, ext = True, intr = True, seed = seed_list[0], load = load, save = save)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.load()\n",
    "evaluate_agent(agent, n_eval_episodes = 1, render = True)  # Intrinsic: 945 mean, Extrinsic: 1386"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up the game\n",
    "* How the rendering works\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "phoenix = \"ALE/Phoenix-v5\"\n",
    "space_invaders = \"ALE/SpaceInvaders-v5\"\n",
    "assault = \"ALE/Assault-v5\"\n",
    "\n",
    "\n",
    "\n",
    "game = env_id = assault\n",
    "\n",
    "env = gym.make(env_id, render_mode = 'human')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show some steps of the chosen game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if wb:\n",
    "    wandb.init(\n",
    "                    project= project_name, \n",
    "\n",
    "                    name = 'random_agent_assault')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run this cell to get some episode of the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peppe/miniconda3/envs/my_env/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:289: UserWarning: \u001b[33mWARN: No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "scores_deque = deque(maxlen = 100)\n",
    "env.reset()\n",
    "rewards_list = []\n",
    "for episode in range(3):\n",
    "        total_reward = 0\n",
    "        done = False\n",
    "        s, _ = env.reset()\n",
    "        rew_list = 0\n",
    "        while not done:\n",
    "            \n",
    "            action = env.action_space.sample()\n",
    "            s, reward, done, truncated, info = env.step(action)\n",
    "   \n",
    "            env.render()\n",
    "            rew_list+=reward\n",
    "        scores_deque.append(rew_list)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing: Result of the image transformation.\n",
    "* This image transformation was selected so as reduce the ambuiguities stemming from the details in the games.\n",
    "* Since the considered video-games have similar rules, setting, and objectives, we want to have similar frame representation in the latent space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phoenix_game = np.load('./images/phoenix.npy')\n",
    "space_invaders_game = np.load('./images/space_invaders.npy')\n",
    "assault_game = np.load('./images/assault.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def plot_nparray_with_torch_transform(np_array):\n",
    "    ''' This function takes as input a numpy array, it applies all the desired transformation with torchvision.transforms, and then it display the new representation \n",
    "        INPUT: np_array: It's a numpy array,\n",
    "        OUTPUT: ----        '''\n",
    "    observation_new = transform(Image.fromarray(np_array))\n",
    "    observation_new = np.array(observation_new)/255\n",
    "    plt.imshow((observation_new), cmap = 'gray')\n",
    "    plt.show()\n",
    "\n",
    "plot_nparray_with_torch_transform(phoenix_game)\n",
    "time.sleep(1)\n",
    "plot_nparray_with_torch_transform(space_invaders_game)\n",
    "time.sleep(1)\n",
    "plot_nparray_with_torch_transform(assault_game)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3d541b27ed3f6b3a2668175b94af942c53fef9dc2000d6033c45f742df07c856"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
